---
title: "Quickstart for R and the DIDE cluster"
author: "Rich FitzJohn"
date: "2017-02-24"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quickstart for R and the DIDE cluster}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



> Get yourself running R jobs on the cluster in 10 minutes or so.

Assumptions that I make here:

* you are using R

* your task can be represented as running a function on some inputs
  to create an output (a file based output is OK)

* you are working on a network share and have this mounted on your
  computer

* you know what packages your code depends on

* your package dependencies are all on CRAN, and are all available
  in windows binary form.

If any of these do not apply to you, you'll probably need to read
the full vignette.  In any case the full vignette contains a bunch
more information anyway.

## Install a lot of packages

Install the packages using [`drat`](https://cran.rstudio.com/package=drat)

```r
# install.package("drat") # if you don't have it already
drat:::add("dide-tools")
install.packages("didehpc")
```

Or, somewhat equivalently

```r
source("https://dide-tools.github.io/didehpc/install")
```

## Describe your computer so we can find things

On windows if you are using a domain machine, you should need only
to select the cluster you want to use

```r
didehpc::didehpc_config_global(cluster = "fi--didemrchnb")
```

Otherwise, and on any other platform you'll need to provide your username:

```r
didehpc::didehpc_config_global(credentials = "yourusername",
                               cluster = "fi--didemrchnb")
```

If you are running Linux we can get both your username and password
from the file you use to mount your network shares (see the main
vignette for details)
```r
didehpc::didehpc_config_global(credentials = "~/.smbcredentials",
                               cluster = "fi--didemrchnb")
```

If this is the first time you have run this package, best to try
out the login proceedure with:

```r
didehpc::web_login()
```

## Describe your project dependencies so we can recreate that on the cluster

Make a vector of packages that you use in your project:

```r
packages <- c("ape", "MASS")
```

And of files that define functions that you ned to run things:

```r
sources <- "mysources.R"
```

If you had a vector here that would be OK too.  The source file
here is very simple:

```r
make_tree <- function(nspp) {
  message("I am building a tree!")
  ape::rtree(nspp)
}

combine <- function(a, b, c) {
  sprintf("%s: %2.5f", a, b + c)
}
```

Then save this together to form a "context".

```r
ctx <- context::context_save("contexts", packages = packages, sources = sources)
```

If you have no packages or no sources, use `NULL` or omit them in
the call below (which is the default anyway).

The first argument here, `"contexts"` is the name of a directory
that we will use to hold a lot of information about your jobs.  You
don't need (or particularly want) to know what is in here.

## Build a queue, based on this context.

This will prompt you for your password, as it will try and log in.

It also installs windows versions of all packages within the
`contexts` directory -- both packages required to get this whole
system working and then the packages required for your particular
jobs.


```r
obj <- didehpc::queue_didehpc(ctx)
```

```
## Loading context d7c0110acaa18c9e68a0353fae50bbd5
```

```
## Already logged in
```

```
## [ download  ]  package database
```

```
## [ deps      ]  7 extra: crayon, digest, ids, openssl, R6, storr, uuid
```

```
## [ cross     ]  ape
```

```
## [ cross     ]  context
```

```
## [ cross     ]  crayon
```

```
## [ cross     ]  digest
```

```
## [ cross     ]  ids
```

```
## [ cross     ]  openssl
```

```
## [ cross     ]  R6
```

```
## [ cross     ]  storr
```

```
## [ cross     ]  uuid
```

Once you get to this point we're ready to start running things on
the cluster.  Let's fire off a test to make sure that everything works OK:

```r
t <- obj$enqueue(sessionInfo())
```

We can poll the job for a while, which will print a progress bar.
If the job is returned in time, it will return the result of
running the function.  Otherwise it will throw an error.

```r
t$wait(120)
```

```
## R version 3.3.2 (2016-10-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows Server 2012 R2 x64 (build 9600)
##
## locale:
## [1] LC_COLLATE=English_United Kingdom.1252
## [2] LC_CTYPE=English_United Kingdom.1252
## [3] LC_MONETARY=English_United Kingdom.1252
## [4] LC_NUMERIC=C
## [5] LC_TIME=English_United Kingdom.1252
##
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base
##
## other attached packages:
## [1] ape_4.1     MASS_7.3-45
##
## loaded via a namespace (and not attached):
## [1] R6_2.2.0        parallel_3.3.2  context_0.1.0   nlme_3.1-128
## [5] grid_3.3.2      digest_0.6.12   storr_1.0.3     lattice_0.20-34
```

You can use `t$result()` to get the result straight away (throwing
an error if it is not ready) or `t$wait(Inf)` to wait forever.

## Running a single task

This is just using the `enqueue` function as above.  But it also
works with functions defined in files passed in as `sources`; here
the function `make_tree`.

```r
t <- obj$enqueue(make_tree(10))
tree <- t$wait(120)
tree
```

```
##
## Phylogenetic tree with 10 tips and 9 internal nodes.
##
## Tip labels:
## 	t4, t1, t2, t9, t7, t8, ...
##
## Rooted; includes branch lengths.
```

The `t` object has a number of other methods you can use:

```r
t
```

```
## <queuer_task>
##   Public:
##     clone: function (deep = FALSE)
##     context_id: function ()
##     expr: function (locals = FALSE)
##     id: 59d79552dd01261df7e4db3de932813e
##     initialize: function (id, root, check_exists = TRUE)
##     log: function (parse = TRUE)
##     result: function (allow_incomplete = FALSE)
##     root: context_root
##     status: function ()
##     times: function (unit_elapsed = "secs")
##     wait: function (timeout, time_poll = 0.5, progress = NULL)
```

Get the result from running a task

```r
t$result()
```

```
##
## Phylogenetic tree with 10 tips and 9 internal nodes.
##
## Tip labels:
## 	t4, t1, t2, t9, t7, t8, ...
##
## Rooted; includes branch lengths.
```

Get the status of the task

```r
t$status()
```

```
## [1] "COMPLETE"
```

(might also be "PENDING", "RUNNING" or "ERROR"

Get the original expression:

```r
t$expr()
```

```
## make_tree(10)
```

Find out how long everything took

```r
t$times()
```

```
##                            task_id           submitted             started
## 1 59d79552dd01261df7e4db3de932813e 2017-02-24 17:26:29 2017-02-24 17:26:29
##              finished   waiting    running      idle
## 1 2017-02-24 17:26:29 0.8056591 0.01562691 0.4974065
```

You may see negative numbers for "waiting" as the submitted time is
based on your computer and started/finished are based on the
cluster.

And get the log from running the task

```r
t$log()
```

```
## [ hello     ]  2017-02-24 17:26:29.578
## [ wd        ]  Q:/cluster_testing/20170224/vignette
## [ bootstrap ]
## [ lib       ]  Q:\cluster_testing\20170224\vignette\contexts/lib/windows/3.3
## [ init      ]  2017-02-24 17:26:29.593
## [ hostname  ]  FI--DIDEMRC76
## [ process   ]  3208
## [ version   ]  0.1.0
## [ open:db   ]  rds
## [ context   ]  d7c0110acaa18c9e68a0353fae50bbd5
## [ library   ]  ape, MASS
## [ namespace ]
## [ source    ]  mysources.R
## [ parallel  ]  running as single core job
## [ root      ]  Q:\cluster_testing\20170224\vignette\contexts
## [ context   ]  d7c0110acaa18c9e68a0353fae50bbd5
## [ task      ]  59d79552dd01261df7e4db3de932813e
## [ expr      ]  make_tree(10)
## [ start     ]  2017-02-24 17:26:29.812
##     I am building a tree!
## [ ok        ]
## [ end       ]  2017-02-24 17:26:29.843
```

There is also a bit of DIDE specific logging that happens before
this point; if the job fails inexplicably the answer may be in:

```r
obj$dide_log(t)
```

```
## generated on host: wpia-dide136.dide.ic.ac.uk
## generated on date: 2017-02-24
## didehpc version: 0.1.0
## context version: 0.1.0
## running on: FI--DIDEMRC76
## mapping Q: -> \\fi--san02\homes\rfitzjoh
## The command completed successfully.
## mapping T: -> \\fi--didef2\tmp
## The command completed successfully.
## working directory: Q:\cluster_testing\20170224\vignette
## this is a single task
## logfile: Q:\cluster_testing\20170224\vignette\contexts\logs\59d79552dd01261df7e4db3de932813e
## Q:\cluster_testing\20170224\vignette>Rscript "Q:\cluster_testing\20170224\vignette\contexts\bin\task_run" "Q:\cluster_testing\20170224\vignette\contexts" 59d79552dd01261df7e4db3de932813e  1>"Q:\cluster_testing\20170224\vignette\contexts\logs\59d79552dd01261df7e4db3de932813e" 2>&1
## Quitting
```

## Running a bunch of tasks

There are two broad options here;

1. Apply a function to each element of a list, similar to `lapply`
with `$lapply`
2. Apply a function to each row of a data.frame perhaps using each
column as a different argument with `$enqueue_bulk`

Suppose we want to make a bunch of trees of different sizes.  This
would involve mapping our `make_tree` function over a vector of
sizes:

```r
sizes <- 3:8
grp <- obj$lapply(sizes, make_tree)
```

```
## Creating bundle: 'undivined_bufeo'
```

```
## submitting 6 tasks
```

By default, `$lapply` returns a "task_bundle" with an
automatically generated name.  You can customise the name with the
`name` argument.

Get the startus of all the jobs

```r
grp$status()
```

```
## dd5cf9e48bf59d6382bb494bb053fcaf cdd375d8c6681447e66df4ddc20a61cc
##                       "COMPLETE"                       "COMPLETE"
## cdad3d3d66b6e26f12daf603505a6bbd 777d5ed8dc67222f84918ffa8774fa88
##                       "COMPLETE"                       "COMPLETE"
## 7b2e0f6b830745bdfe18d4389a0ccbaa 5b7d638ef83ffb9b03a570a53a99dd06
##                       "COMPLETE"                        "PENDING"
```

Wait until they are all complete and get the results

```r
res <- grp$wait(120)
```

The other bulk interface is where you want to run a function over a
combination of parameters.  Use `$enqueue_bulk` here.

```r
pars <- expand.grid(a = letters[1:3], b = runif(2), c = pi,
                    stringsAsFactors = FALSE)
pars
```

```
##   a         b        c
## 1 a 0.8983897 3.141593
## 2 b 0.8983897 3.141593
## 3 c 0.8983897 3.141593
## 4 a 0.9446753 3.141593
## 5 b 0.9446753 3.141593
## 6 c 0.9446753 3.141593
```

```r
grp <- obj$enqueue_bulk(pars, combine, do_call = TRUE)
```

```
## Creating bundle: 'potential_mockingbird'
```

```
## submitting 6 tasks
```

By default this runs

* `combine(a = pars$a[[1]], b = pars$b[[1]], c = pars$c[[1]])`
* `combine(a = pars$a[[2]], b = pars$b[[2]], c = pars$c[[2]])`
* ...
* `combine(a = pars$a[[6]], b = pars$b[[6]], c = pars$c[[6]])`


```r
res <- grp$wait(120)
res
```

```
## [[1]]
## [1] "a: 4.03998"
##
## [[2]]
## [1] "b: 4.03998"
##
## [[3]]
## [1] "c: 4.03998"
##
## [[4]]
## [1] "a: 4.08627"
##
## [[5]]
## [1] "b: 4.08627"
##
## [[6]]
## [1] "c: 4.08627"
```
