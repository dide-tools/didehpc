<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Rich FitzJohn" />

<meta name="date" content="2017-05-11" />

<title>R and the DIDE cluster</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">R and the DIDE cluster</h1>
<h4 class="author"><em>Rich FitzJohn</em></h4>
<h4 class="date"><em>2017-05-11</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#functions">Functions</a></li>
<li><a href="#filesystems">Filesystems</a></li>
<li><a href="#getting-started">Getting started</a><ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#contexts">Contexts</a></li>
<li><a href="#creating-the-queue">Creating the queue</a></li>
<li><a href="#testing-that-the-queue-works-correctly">Testing that the queue works correctly</a></li>
<li><a href="#running-single-jobs">Running single jobs</a></li>
<li><a href="#running-many-jobs">Running many jobs</a></li>
<li><a href="#cancelling-and-stopping-jobs">Cancelling and stopping jobs</a></li>
</ul></li>
<li><a href="#misc">Misc</a><ul>
<li><a href="#jobs-that-require-compiled-code">Jobs that require compiled code</a></li>
<li><a href="#parallel-computation-on-the-cluster">Parallel computation on the cluster</a></li>
<li><a href="#running-heaps-of-jobs-without-annoying-your-colleagues">Running heaps of jobs without annoying your colleagues</a></li>
<li><a href="#rstan"><code>rstan</code></a></li>
<li><a href="#using-microsoft-hpc-tools">Using Microsoft HPC tools</a></li>
</ul></li>
<li><a href="#mapping-network-drives">Mapping network drives</a><ul>
<li><a href="#windows">Windows</a></li>
<li><a href="#mac-osx">Mac OS/X</a></li>
<li><a href="#linux">Linux</a></li>
</ul></li>
<li><a href="#running-out-of-place">Running out of place</a></li>
</ul>
</div>

<p>Parallel computing on a cluster can be more challenging than running things locally because it’s often the first time that you need to package up code to run elsewhere, and when things go wrong it’s more difficult to get information on why things failed.</p>
<p>Much of the difficulty of getting things running involves working out what your code depends on, and getting that installed in the right place on a computer that you can’t physically poke at. The next set of problems is dealing with the balloning set of files that end up being created - templates, scripts, output files, etc.</p>
<p>This set of packages (<a href="https://github.com/mrc-ide/didehpc"><code>didehpc</code></a>, <a href="https://github.com/richfitz/queuer"><code>queuer</code></a> and <a href="https://github.com/mrc-ide/context"><code>context</code></a>, along with a couple of support packages (<a href="https://github.com/richfitz/provisionr"><code>provisionr</code></a>, <a href="https://github.com/richfitz/buildr"><code>buildr</code></a>, <a href="https://github.com/richfitz/syncr"><code>syncr</code></a>, <a href="https://github.com/richfitz/rrq"><code>rrq</code></a> and <a href="https://github.com/richfitz/storr"><code>storr</code></a>) aims to remove the pain of getting everything set up, and getting cluster tasks running, and retrieving your results.</p>
<p>Once everything is set up, running a job on the cluster should be as straightforward as running things locally.</p>
<p>The documentation here runs through a few of the key concepts, then walks through setting this all up. There’s also a “quick start” guide that contains much less discussion.</p>
<div id="functions" class="section level2">
<h2>Functions</h2>
<p>The biggest conceptual move is from thinking about running <strong>scripts</strong> that generate <em>files</em> to running <strong>functions</strong> that return <em>objects</em>. The reason for this is that gives a well defined interface to build everything else around.</p>
<p>The problem with scripts is that they might do almost anything. They depend on untold files and packages which they load wherever. The produce any number of objects. That’s fine, but it becomes hard to reason about them to plan deploying them elsewhere, to capture the outputs appropriately, or to orchestrate looping over a bunch of paramter values. If you’ve found yourself writing a number of script files changing values with text substitution you have run into this.</p>
<p>In contrast, functions do (ideally) one thing. They have a well defined set of inputs (their arguments) and outputs (their return value). We can loop over a range of input values by iterating over a set of arguments.</p>
<p>This set of packages tends to work best if you let it look after filenames. Rather than trying to come up with a naming scheme for different files as based on parameter values, just return objects and the packages will arrange for them to be saved and reloaded.</p>
</div>
<div id="filesystems" class="section level2">
<h2>Filesystems</h2>
<p>The DIDE cluster needs everything to be available on a filesystem that the cluster can read. Practically this means the filesystems <code>//fi--didef2/tmp</code> or <code>//fi--san03/homes/username</code> and the like. You probably have access to network shares that are specific to a project, too. For Windows users these are probably mapped to drives (<code>Q:</code> or <code>T:</code> or similar) already, but for other platforms you will need to do a little extra work to get things set up (see below).</p>
<p>It is simplest if <em>everything</em> that is needed for a project is present in a single directory that is visible on the cluster. However, other patterns are possible; see “Running out of place” towards the bottom of this page.</p>
<p>However for the most of this document I will assume that everything is in one directory, which is on a network share.</p>
</div>
<div id="getting-started" class="section level1">
<h1>Getting started</h1>
<p>The initial setup will feel like a headache at first, but it should ultimately take only a few lines. Once everything is set up, then the payback is that is the job submission part will become a lot simpler.</p>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>Install the packages using <a href="https://cran.rstudio.com/package=drat"><code>drat</code></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.package(&quot;drat&quot;) # if you don't have it already</span>
drat:::<span class="kw">add</span>(<span class="st">&quot;mrc-ide&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;didehpc&quot;</span>)</code></pre></div>
<p>Or, somewhat equivalently</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;https://mrc-ide.github.io/didehpc/install&quot;</span>)</code></pre></div>
<p>Be sure to run this in a fresh session.</p>
</div>
<div id="configuration" class="section level2">
<h2>Configuration</h2>
<p>The configuration is handled in a two stage process. First, some bits that are machine specific are set using <code>options</code> with option names that are prefixed with <code>didehpc</code>. Then when a queue is created, further values can be passed along via the <code>config</code> argument that will use the “global” options as a default.</p>
<p>The reason for this separation is that ideally the machine-specific options will not end up in scripts, because that makes things less portable (for example, we need to get your username, but your username is unlikely to work for your collaborators).</p>
<p>Ideally in your ~/.Rprofile file, you will add something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(
  <span class="dt">didehpc.username =</span> <span class="st">&quot;rfitzjoh&quot;</span>,
  <span class="dt">didehpc.home =</span> <span class="st">&quot;~/net/home&quot;</span>)</code></pre></div>
<p>and then set only options (such as cluster and cores or template) that vary with a project.</p>
<p>If you use the “big” cluster, you can add <code>didehpc.cluster = &quot;fi--didemrchnb&quot;</code> here.</p>
<p>At the moment (while things change) it might be simplest to set things using the <code>didehpc::didehpc_config_global</code> function. The help file <code>?didehpc::didehpc_config</code> outlines the options here. At the moment a minimal set of options is your credentials (not needed on Windows domain machines) and the cluster you wish to use (if you don’t want to use the small cluster).</p>
<p>There are lots of configuration options that can be tweaked, but I suggest setting things this way <em>only</em> for things that will hold for all projects.</p>
<div id="credentials" class="section level3">
<h3>Credentials</h3>
<p>Windows users will not need to provide anything unless they are on a non-domain machine or they are in the unfortunate situation of juggling multiple usernames across systems. Non-domain machines will need the credentials set as above.</p>
<p>Mac users will need to provide their username here as above.</p>
<p>If you have a Linux system and have configured your smb mounts as described below, you might as well take advantage of this and set <code>credentials = &quot;~/.smbcredentials&quot;</code> and you will never be prompted for your password:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">didehpc.credentials =</span> <span class="st">&quot;~/.smbcredentials&quot;</span>)</code></pre></div>
</div>
<div id="seeing-the-default-configuration" class="section level3">
<h3>Seeing the default configuration</h3>
<p>To see the configuration that will be run if you don’t do anything (else), run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">didehpc::<span class="kw">didehpc_config</span>()</code></pre></div>
<pre><code>## &lt;didehpc_config&gt;
##  - cluster: fi--didemrchnb
##  - credentials: ~/.smbcredentials
##  - username: rfitzjoh
##  - build_server: builderhv.dide.ic.ac.uk
##  - template: GeneralNodes
##  - hpctools: FALSE
##  - resource:
##     - parallel: FALSE
##     - count: 1
##     - type: Cores
##  - shares:
##     - home: (local) /home/rich/net/home =&gt; //fi--san03/homes/rfitzjoh =&gt; Q: (remote)
##     - temp: (local) /home/rich/net/temp =&gt; //fi--didef2/tmp =&gt; T: (remote)
##  - use_workers: FALSE
##  - use_rrq: FALSE
##  - worker_timeout: 600
##  - rtools: FALSE
##  - r_version: 3.3.2</code></pre>
<p>In here you can see the cluster (here, <code>fi--didemrchnb</code>), credentials and username, the job template (<code>GeneralNodes</code>), information about the resources that will be requested (1 core) and information on filesystem mappings. There are a few other bits of information that may be explained further down. The possible options are explained further in <code>?didehpc::didehpc_config</code></p>
</div>
<div id="additional-shares" class="section level3">
<h3>Additional shares</h3>
<p>If you refer to network shares in your functions, e.g., to refer to data, you’ll need to map these too. To do that, pass them as the <code>shares</code> argument to <code>didehpc_config_global</code>.</p>
<p>To describe each share, use the <code>didehpc::path_mapping</code> function which takes arguments:</p>
<ul>
<li>name: a desctiptive name for the share</li>
<li><code>path_local</code>: the point where the share is mounted on your computer</li>
<li><code>path_remote</code>: the network path that the share refers to (forward slashes are much easier to enter here than backward slashes)</li>
<li><code>drive_remote</code>: the drive this should be mapped to on the cluster.</li>
</ul>
<p>So to map your “M drive” to which points at <code>\\fi--didef2\malaria</code> to <code>M:</code> on the cluster you can write</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">share &lt;-<span class="st"> </span>didehpc::<span class="kw">path_mapping</span>(<span class="st">&quot;malaria&quot;</span>, <span class="st">&quot;M:&quot;</span>, <span class="st">&quot;//fi--didef2/malaria&quot;</span>, <span class="st">&quot;M:&quot;</span>)
config &lt;-<span class="st"> </span>didehpc::<span class="kw">didehpc_config</span>(<span class="dt">shares =</span> share)</code></pre></div>
<p>If you have more than one share to map, pass them through as a list (e.g., <code>didehpc::didehpc_config(shares = list(share1, share2, ...))</code>).</p>
<p>For most systems we <code>didehpc</code> will do a reasonable job of detecting the shares that you are running on, so this should (hopefully) only be necessary for detecting additional shares. The issue there is that you’ll need to use absolute paths to refer to the resources and that’s going to complicate things…</p>
</div>
</div>
<div id="contexts" class="section level2">
<h2>Contexts</h2>
<p>To recreate your work environment on the cluster, we use a package called <code>context</code>. This package uses the assumption that most working environments can be recreated by a combination of R packages and sourcing a set of function definitions.</p>
<p>In order to have the system tell you more about what it is doing, you can (optionally) run this command. This can be a bit more reassuring during long-running setup stages</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">context::<span class="kw">context_log_start</span>()</code></pre></div>
<div id="root" class="section level3">
<h3>Root</h3>
<p>Every context has a “root”; this is the directory that everything will be saved in. Most of the examples in the help use <code>contexts</code> which is fairly self explanatory but it can be any directory. Generally it will be in the current directory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">root &lt;-<span class="st"> &quot;contexts&quot;</span></code></pre></div>
<p>This directory is going to get large over time and will eventually need to be deleted. Eventually I will come up with some tools to simplify working with these. In the meantime, treat these as somewhat disposable.</p>
</div>
<div id="packages" class="section level3">
<h3>Packages</h3>
<p>If you list packages as a character vector then all packages will be installed for you, and they will also be <em>attached</em>; this is what happens when you use the function <code>library()</code> So for example if you need to depend on the <code>rstan</code> and <code>ape</code> packages you could write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctx &lt;-<span class="st"> </span>context::<span class="kw">context_save</span>(root, <span class="dt">packages =</span> <span class="kw">c</span>(<span class="st">&quot;rstan&quot;</span>, <span class="st">&quot;ape&quot;</span>))</code></pre></div>
<p>Attaching packages is not always what is wanted, especially if you have packages that clobber functions in base packages (e.g., <code>dplyr</code>!). An alternative is to list a set of packages that you want installed and split them into packages you would like attached and packages you would only like loaded:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">packages &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">loaded =</span> <span class="st">&quot;geiger&quot;</span>, <span class="dt">attached =</span> <span class="st">&quot;ape&quot;</span>)
ctx &lt;-<span class="st"> </span>context::<span class="kw">context_save</span>(root, <span class="dt">packages =</span> packages)</code></pre></div>
<p>In this case, the packages in the <code>loaded</code> section will be installed (along with their dependencies) and before anything runs, we will run <code>loadNamespace</code> on them to confirm that they are properly available. Access functions in this package with the double-colon operator, like <code>geiger::fitContinuous</code>. However they will not be attached so will not modify the search path.</p>
<p>In contrast, packages listed in <code>attached</code> will be loaded with <code>library</code> so they will be available without qualification (e.g., <code>read.tree</code> rather than <code>ape::read.tree</code>).</p>
</div>
<div id="source-files-for-function-definitions" class="section level3">
<h3>Source files for function definitions</h3>
<p>If you define any of your own functions you will need to tell the cluster about them. The easiest way to do this is to save them in a file that contains only function definitions (and does not read data, etc).</p>
<p>For example, I have a file <code>mysources.R</code> with a very simple tree simulation in it. Imagine this is some slow function that given an integer <code>nspp</code> after a bunch of calculation yields a tree with <code>nspp</code> tips:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">make_tree &lt;-<span class="st"> </span>function(nspp) {
  <span class="kw">message</span>(<span class="st">&quot;I am building a tree!&quot;</span>)
  ape::<span class="kw">rtree</span>(nspp)
}

combine &lt;-<span class="st"> </span>function(a, b, c) {
  <span class="kw">sprintf</span>(<span class="st">&quot;%s: %2.5f&quot;</span>, a, b +<span class="st"> </span>c)
}</code></pre></div>
<p>To set this up, we’d write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctx &lt;-<span class="st"> </span>context::<span class="kw">context_save</span>(root, <span class="dt">packages =</span> <span class="st">&quot;ape&quot;</span>, <span class="dt">sources =</span> <span class="st">&quot;mysources.R&quot;</span>)</code></pre></div>
<pre><code>## [ open:db   ]  rds</code></pre>
<p><code>sources</code> can be a character vector, <code>NULL</code> or <code>character(0)</code> if you have no sources, or just omit it as above.</p>
</div>
<div id="custom-packages" class="section level3">
<h3>Custom packages</h3>
<p>If you depend on packages that are not on CRAN (e.g., your personal research code) you’ll need to tell <code>context</code> where to find them with its <code>package_sources</code> argument.</p>
<p>If the packages are on GitHub and public you can pass the github username/repo pair, in <code>devtools</code> style:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">context::<span class="kw">context_save</span>(...,
  <span class="dt">package_sources =</span> provisionr::<span class="kw">package_sources</span>(<span class="dt">github =</span> <span class="st">&quot;richfitz/kitten&quot;</span>))</code></pre></div>
<p>Like with <code>devtools</code> you can use subdirectories, specific commits or tags in the specification.</p>
<p>If the packages are private, it is simplest to pass the path to where the package can be found on your computer with the <code>local</code> argument to <code>package_sources</code>.</p>
</div>
</div>
<div id="creating-the-queue" class="section level2">
<h2>Creating the queue</h2>
<p>Once a context has been created, we can create a queue with it. This is separate from the actual cluster queue, but will be our interface to it. Running this step takes a while because it installs all the packages that the cluster will need into the context directory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj &lt;-<span class="st"> </span>didehpc::<span class="kw">queue_didehpc</span>(ctx)</code></pre></div>
<pre><code>## Loading context ef7ddced8cd41ed7c5d1a73201fd93d8</code></pre>
<pre><code>## [ context   ]  ef7ddced8cd41ed7c5d1a73201fd93d8</code></pre>
<pre><code>## [ library   ]  ape</code></pre>
<pre><code>## [ namespace ]</code></pre>
<pre><code>## [ source    ]  mysources.R</code></pre>
<pre><code>## [ provision ]  library at contexts/lib/windows/3.3</code></pre>
<pre><code>## [ download  ]  package database</code></pre>
<p>If the above command does not throw an error, then you have successfully logged in. When you run <code>queue_didehpc</code> it will install windows versions of all required packages within the <code>root</code> directory (here, “contexts”). This is necessary even when you are on windows because the cluster cannot see files that are on your computer.</p>
<p><code>obj</code> is a weird sort of object called an <code>R6</code> class. It’s a bit like a Python or Java class if you’ve come from those languages. The thing you need to know is that the object is like a list and contains a number of functions that can be run by runing <code>obj$functionname()</code>. These functions all act by <em>side effect</em>; they interact with a little database stored in the context root directory or by communicating with the cluster using the web interface that Wes created.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj</code></pre></div>
<pre><code>## &lt;queue_didehpc&gt;
##   Inherits from: &lt;queue_base&gt;
##   Public:
##     clone: function (deep = FALSE)
##     cluster_load: function (cluster = NULL, nodes = TRUE)
##     config: didehpc_config
##     context: context
##     db: storr, R6
##     dide_id: function (t)
##     dide_log: function (t)
##     enqueue: function (expr, envir = parent.frame(), submit = TRUE, name = NULL)
##     enqueue_: function (expr, envir = parent.frame(), submit = TRUE, name = NULL)
##     enqueue_bulk: function (X, FUN, ..., do_call = TRUE, envir = parent.frame(),
##     initialize: function (context, config, root, initialise, sync)
##     initialize_context: function ()
##     lapply: function (X, FUN, ..., envir = parent.frame(), timeout = 0, time_poll = 1,
##     logged_in: TRUE
##     login: function (always = TRUE)
##     preflight: function ()
##     provision: function (installed_action = &quot;upgrade&quot;, refresh_drat = FALSE)
##     provisioned: TRUE
##     root: context_root
##     rrq: NULL
##     rrq_controller: function ()
##     stop_workers: function (worker_ids = NULL)
##     submit: function (task_ids, names = NULL)
##     submit_or_delete: function (task_ids, name = NULL)
##     submit_workers: function (n, timeout = 600, progress = NULL)
##     sync: NULL
##     sync_files: function (verbose = TRUE, delete = TRUE)
##     task_bundle_get: function (name)
##     task_bundle_info: function ()
##     task_bundle_list: function ()
##     task_delete: function (task_ids)
##     task_get: function (task_id, check_exists = TRUE)
##     task_list: function ()
##     task_result: function (task_id)
##     task_status: function (task_ids = NULL, named = TRUE)
##     task_status_dide: function (task_ids = NULL)
##     task_times: function (task_ids = NULL, unit_elapsed = &quot;secs&quot;, sorted = TRUE)
##     templates: list
##     unsubmit: function (t)
##     workdir: /home/rich/net/home/cluster_testing/20170511/vignette
##     worker_controller: function ()
##     workers: NULL</code></pre>
<p>For example, to list the tasks that we know about:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">task_list</span>()</code></pre></div>
<pre><code>##  [1] &quot;00acc4378592c907663dc5d7583d7bdc&quot; &quot;1ef9048c5a3448bcf898237e38cd2cd5&quot;
##  [3] &quot;26fb414ef7da5d3e011b16b84599b1ae&quot; &quot;41389dd7146594b3e882e63473abb7a7&quot;
##  [5] &quot;4239c8afdcf2638ab02b62b03e59e0b8&quot; &quot;48a2472187aa5deb778d05e571819a54&quot;
##  [7] &quot;4ea253e5c84be5cd529909ee45ff0028&quot; &quot;5ff5a054e96dde6e30aa9afaf12f74a6&quot;
##  [9] &quot;65e32538db836775d801722f037fc298&quot; &quot;679dce0e2b6ef1d9f283f0d54011e9b8&quot;
## [11] &quot;6e1afb3935fa2b2d758d0468f5001a85&quot; &quot;8ffe17494dfcc9c8d0f3a59cca42dcb1&quot;
## [13] &quot;9a0fc63271c351b3bdb5008c457d0b60&quot; &quot;a2c9de29a6c351d2055589f466fb3e80&quot;
## [15] &quot;aea97fa47effdea5021e32ead8762078&quot; &quot;b220426c67143575c3667ff5f11735f0&quot;
## [17] &quot;b5ac88d3cc6a118676f6f3030e8aeb64&quot; &quot;da822ceb4d61b2f8f0bf2049b1271f81&quot;
## [19] &quot;da9f35555f6ef30a1fcaecc70e30c669&quot; &quot;f602835e76cf863a5d8a67090ef94037&quot;
## [21] &quot;f6e05621248c45f23c48552396e70c33&quot; &quot;fc3808164d4ff992bb6cb2d0bd286fb7&quot;</code></pre>
<p>(of course there are no tasks yet because we haven’t added any). As a slightly more interesting example we can see how busy the cluster is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">cluster_load</span>()</code></pre></div>
<pre><code>##           name free used total % used
## -------------- ---- ---- ----- ------
##  fi--didemrc06    0   12    12   100%
##  fi--didemrc07    0   12    12   100%
##  fi--didemrc08    0   12    12   100%
##  fi--didemrc09    0   12    12   100%
##  fi--didemrc10    0   12    12   100%
##  fi--didemrc11    0   12    12   100%
##  fi--didemrc12    0   12    12   100%
##  fi--didemrc13   24    0    24     0%
##  fi--didemrc14   24    0    24     0%
##  fi--didemrc15   24    0    24     0%
##  fi--didemrc16   24    0    24     0%
##  fi--didemrc17    0   12    12   100%
##  fi--didemrc18    0   12    12   100%
##  fi--didemrc19    0   12    12   100%
##  fi--didemrc20    0   12    12   100%
##  fi--didemrc21    0   12    12   100%
##  fi--didemrc22    0   12    12   100%
##  fi--didemrc23    0   12    12   100%
##  fi--didemrc24    0   12    12   100%
##  fi--didemrc25    0   12    12   100%
##  fi--didemrc26    0   12    12   100%
##  fi--didemrc27   11    1    12     8%
##  fi--didemrc28   12    0    12     0%
##  fi--didemrc38   16    0    16     0%
##  fi--didemrc39   16    0    16     0%
##  fi--didemrc40   16    0    16     0%
##  fi--didemrc41   16    0    16     0%
##  fi--didemrc42   16    0    16     0%
##  fi--didemrc43   16    0    16     0%
##  fi--didemrc44   16    0    16     0%
##  fi--didemrc45   16    0    16     0%
##  fi--didemrc46   16    0    16     0%
##  fi--didemrc47   16    0    16     0%
##  fi--didemrc48   16    0    16     0%
##  fi--didemrc49   16    0    16     0%
##  fi--didemrc50    0   16    16   100%
##  fi--didemrc51   20    0    20     0%
##  fi--didemrc52   20    0    20     0%
##  fi--didemrc53   20    0    20     0%
##  fi--didemrc54   20    0    20     0%
##  fi--didemrc55   20    0    20     0%
##  fi--didemrc56   20    0    20     0%
##  fi--didemrc57   20    0    20     0%
##  fi--didemrc58   20    0    20     0%
##  fi--didemrc59   20    0    20     0%
##  fi--didemrc60   20    0    20     0%
##  fi--didemrc61   20    0    20     0%
##  fi--didemrc62   20    0    20     0%
##  fi--didemrc63   20    0    20     0%
##  fi--didemrc64   20    0    20     0%
##  fi--didemrc65    0   32    32   100%
##  fi--didemrc66   32    0    32     0%
##  fi--didemrc67    0   24    24   100%
##  fi--didemrc68    0   24    24   100%
##  fi--didemrc69    0   24    24   100%
##  fi--didemrc70    0   24    24   100%
##  fi--didemrc71    0   24    24   100%
##  fi--didemrc72    0   24    24   100%
##  fi--didemrc73    0   24    24   100%
##  fi--didemrc74    0   24    24   100%
##  fi--didemrc75   16    0    16     0%
##  fi--didemrc76   16    0    16     0%
##  fi--didemrc77   16    0    16     0%
##  fi--didemrc78    0   28    28   100%
## -------------- ---- ---- ----- ------
## fi--didemrchnb  671  473  1144    41%</code></pre>
<p>(if you’re on a ANSI-compatible terminal this will be in glorious colour).</p>
</div>
<div id="testing-that-the-queue-works-correctly" class="section level2">
<h2>Testing that the queue works correctly</h2>
<p>Before running a real job, let’s test that everything works correctly by running the <code>sessionInfo</code> command on the cluster. When run locally, <code>sessionInfo</code> prints information about the state of your R session:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.3.3 (2017-03-06)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 18
##
## locale:
##  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
##  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
##  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
##  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C
## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
##
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  base
##
## other attached packages:
## [1] ape_4.1
##
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.10     lattice_0.20-34  crayon_1.3.2     digest_0.6.12
##  [5] grid_3.3.3       context_0.1.1    R6_2.2.0         nlme_3.1-131
##  [9] storr_1.1.0      magrittr_1.5     evaluate_0.10    httr_1.2.1
## [13] stringi_1.1.3    curl_2.2         rematch_1.0.1    whisker_0.3-2
## [17] xml2_1.0.0       queuer_0.1.0     tools_3.3.3      stringr_1.2.0
## [21] parallel_3.3.3   rversions_1.0.3  didehpc_0.1.1    provisionr_0.1.1
## [25] knitr_1.15.1     methods_3.3.3</code></pre>
<p>To run this on the cluster, we wrap it in <code>obj$enqueue</code>. This prevents the evaluation of the expression and instead organises it to be run on the cluster:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t &lt;-<span class="st"> </span>obj$<span class="kw">enqueue</span>(<span class="kw">sessionInfo</span>())</code></pre></div>
<p>We can then poll the cluster for results until it completes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">wait</span>(<span class="dv">100</span>)</code></pre></div>
<pre><code>## R version 3.3.2 (2016-10-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows Server 2012 R2 x64 (build 9600)
##
## locale:
## [1] LC_COLLATE=English_United Kingdom.1252
## [2] LC_CTYPE=English_United Kingdom.1252
## [3] LC_MONETARY=English_United Kingdom.1252
## [4] LC_NUMERIC=C
## [5] LC_TIME=English_United Kingdom.1252
##
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base
##
## other attached packages:
## [1] ape_4.1
##
## loaded via a namespace (and not attached):
## [1] R6_2.2.1        parallel_3.3.2  context_0.1.1   nlme_3.1-128
## [5] grid_3.3.2      digest_0.6.12   storr_1.1.0     lattice_0.20-34</code></pre>
<p>(see the next section for more information about this).</p>
<p>The important part to notice here is that the R “Platform” (second and third line) is Windows Server, as opposed to the host machine which is running Linux. In addition note that <code>ape</code> is lited under “other attached packages” and that <code>context</code>, as well as some other packages (<code>R6</code> <code>storr</code> and <code>digest</code> in particular) have been installed and are loaded (but not attached). This shows that the system has set up a working environment like our local one on the remote machine, and we can evaluate tasks in it!</p>
</div>
<div id="running-single-jobs" class="section level2">
<h2>Running single jobs</h2>
<p>Let’s run something more interesting now by running the <code>make_tree</code> function defined in the <code>mysources.R</code> file.</p>
<p>As above, jobs are queueed by running:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t &lt;-<span class="st"> </span>obj$<span class="kw">enqueue</span>(<span class="kw">make_tree</span>(<span class="dv">10</span>))</code></pre></div>
<p>Like the queue object, <code>obj</code>, task objects are R6 objects that can be used to get information and results back from the task.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t</code></pre></div>
<pre><code>## &lt;queuer_task&gt;
##   Public:
##     clone: function (deep = FALSE)
##     context_id: function ()
##     expr: function (locals = FALSE)
##     id: 2fb96f51ac66118372ba687142d21c6b
##     initialize: function (id, root, check_exists = TRUE)
##     log: function (parse = TRUE)
##     result: function (allow_incomplete = FALSE)
##     root: context_root
##     status: function ()
##     times: function (unit_elapsed = &quot;secs&quot;)
##     wait: function (timeout, time_poll = 0.5, progress = NULL)</code></pre>
<p>the task’s status</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">status</span>()</code></pre></div>
<pre><code>## [1] &quot;PENDING&quot;</code></pre>
<p>…which will move from <code>PENDING</code> to <code>RUNNING</code> to <code>COMPLETE</code> or <code>ERROR</code>. You can get information on submission and running times</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">times</span>()</code></pre></div>
<pre><code>##                            task_id           submitted started finished
## 1 2fb96f51ac66118372ba687142d21c6b 2017-05-11 11:02:33    &lt;NA&gt;     &lt;NA&gt;
##     waiting running idle
## 1 0.5808313      NA   NA</code></pre>
<p>and you can try and get the result of running the task:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">result</span>()</code></pre></div>
<pre><code>## Error: task 2fb96f51ac66118372ba687142d21c6b is unfetchable: PENDING</code></pre>
<p>The <code>wait</code> function, used above, is like <code>result</code> but it will repeatedly poll for the task to be completed for up to <code>timeout</code> seconds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">wait</span>(<span class="dv">100</span>)</code></pre></div>
<pre><code>##
## Phylogenetic tree with 10 tips and 9 internal nodes.
##
## Tip labels:
##  t6, t5, t10, t8, t9, t7, ...
##
## Rooted; includes branch lengths.</code></pre>
<p>once the task has completed, <code>t$result()</code> and <code>t$wait</code> are equivalent</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">result</span>()</code></pre></div>
<pre><code>##
## Phylogenetic tree with 10 tips and 9 internal nodes.
##
## Tip labels:
##  t6, t5, t10, t8, t9, t7, ...
##
## Rooted; includes branch lengths.</code></pre>
<p>Every task creates a log:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">log</span>()</code></pre></div>
<pre><code>## [ hello     ]  2017-05-11 11:02:34.409
## [ wd        ]  Q:/cluster_testing/20170511/vignette
## [ bootstrap ]
## [ lib       ]  Q:\cluster_testing\20170511\vignette\contexts/lib/windows/3.3
## [ init      ]  2017-05-11 11:02:34.440
## [ hostname  ]  FI--DIDEMRC27
## [ process   ]  5972
## [ version   ]  0.1.1
## [ open:db   ]  rds
## [ context   ]  ef7ddced8cd41ed7c5d1a73201fd93d8
## [ library   ]  ape
## [ namespace ]
## [ source    ]  mysources.R
## [ parallel  ]  running as single core job
## [ root      ]  Q:\cluster_testing\20170511\vignette\contexts
## [ context   ]  ef7ddced8cd41ed7c5d1a73201fd93d8
## [ task      ]  2fb96f51ac66118372ba687142d21c6b
## [ expr      ]  make_tree(10)
## [ start     ]  2017-05-11 11:02:34.706
##     I am building a tree!
## [ ok        ]
## [ end       ]  2017-05-11 11:02:34.753
##     Warning message:
##     package 'ape' was built under R version 3.3.3</code></pre>
<p>Warning messages and other output will be printed here. So if you include <code>message()</code>, <code>cat()</code> or <code>print()</code> calls in your task they will appear between <code>start</code> and <code>end</code>.</p>
<p>There is another bit of log that happens before this and contains information about getting the system started up. You should only need to look at this when a job seems to get stuck with status <code>PENDING</code> for ages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">dide_log</span>(t)</code></pre></div>
<pre><code>## generated on host: wpia-dide136.dide.ic.ac.uk
## generated on date: 2017-05-11
## didehpc version: 0.1.1
## context version: 0.1.1
## running on: FI--DIDEMRC27
## mapping Q: -&gt; \\fi--san03\homes\rfitzjoh
## The command completed successfully.
## mapping T: -&gt; \\fi--didef2\tmp
## The command completed successfully.
## working directory: Q:\cluster_testing\20170511\vignette
## this is a single task
## logfile: Q:\cluster_testing\20170511\vignette\contexts\logs\2fb96f51ac66118372ba687142d21c6b
## Q:\cluster_testing\20170511\vignette&gt;Rscript &quot;Q:\cluster_testing\20170511\vignette\contexts\bin\task_run&quot; &quot;Q:\cluster_testing\20170511\vignette\contexts&quot; 2fb96f51ac66118372ba687142d21c6b  1&gt;&quot;Q:\cluster_testing\20170511\vignette\contexts\logs\2fb96f51ac66118372ba687142d21c6b&quot; 2&gt;&amp;1
## Quitting</code></pre>
<p>The queue knows which tasks it has created and you can list them:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">task_list</span>()</code></pre></div>
<pre><code>##  [1] &quot;00acc4378592c907663dc5d7583d7bdc&quot; &quot;1ef9048c5a3448bcf898237e38cd2cd5&quot;
##  [3] &quot;26fb414ef7da5d3e011b16b84599b1ae&quot; &quot;2fb96f51ac66118372ba687142d21c6b&quot;
##  [5] &quot;41389dd7146594b3e882e63473abb7a7&quot; &quot;4239c8afdcf2638ab02b62b03e59e0b8&quot;
##  [7] &quot;48a2472187aa5deb778d05e571819a54&quot; &quot;4ea253e5c84be5cd529909ee45ff0028&quot;
##  [9] &quot;53c1d30c6a7953c1a9d3054653c2de12&quot; &quot;5ff5a054e96dde6e30aa9afaf12f74a6&quot;
## [11] &quot;65e32538db836775d801722f037fc298&quot; &quot;679dce0e2b6ef1d9f283f0d54011e9b8&quot;
## [13] &quot;6e1afb3935fa2b2d758d0468f5001a85&quot; &quot;8ffe17494dfcc9c8d0f3a59cca42dcb1&quot;
## [15] &quot;9a0fc63271c351b3bdb5008c457d0b60&quot; &quot;a2c9de29a6c351d2055589f466fb3e80&quot;
## [17] &quot;aea97fa47effdea5021e32ead8762078&quot; &quot;b220426c67143575c3667ff5f11735f0&quot;
## [19] &quot;b5ac88d3cc6a118676f6f3030e8aeb64&quot; &quot;da822ceb4d61b2f8f0bf2049b1271f81&quot;
## [21] &quot;da9f35555f6ef30a1fcaecc70e30c669&quot; &quot;f602835e76cf863a5d8a67090ef94037&quot;
## [23] &quot;f6e05621248c45f23c48552396e70c33&quot; &quot;fc3808164d4ff992bb6cb2d0bd286fb7&quot;</code></pre>
<p>The long identifiers are random and are long enough that collisions are unlikely.</p>
<p>Notice that the task ran remotely but we never had to indicate which filename things were written to. There is a small database based on <a href="https://richfitz.github.com/storr"><code>storr</code></a> that holds all the information within the context root (here, “contexts”). This means you can close down R and later on regenerate the <code>ctx</code> and <code>obj</code> objects and recreate the task objects, and re-get your results. But at the same time it provides the <em>illusion</em> that the cluster has passed an object directly back to you.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">id &lt;-<span class="st"> </span>t$id
id</code></pre></div>
<pre><code>## [1] &quot;2fb96f51ac66118372ba687142d21c6b&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t2 &lt;-<span class="st"> </span>obj$<span class="kw">task_get</span>(id)
t2$<span class="kw">result</span>()</code></pre></div>
<pre><code>##
## Phylogenetic tree with 10 tips and 9 internal nodes.
##
## Tip labels:
##  t6, t5, t10, t8, t9, t7, ...
##
## Rooted; includes branch lengths.</code></pre>
</div>
<div id="running-many-jobs" class="section level2">
<h2>Running many jobs</h2>
<p>There are two broad options here;</p>
<ol style="list-style-type: decimal">
<li>Apply a function to each element of a list, similar to <code>lapply</code> with <code>$lapply</code></li>
<li>Apply a function to each row of a data.frame perhaps using each column as a different argument with <code>$enqueue_bulk</code></li>
</ol>
<p>The second approach is more general and <code>$lapply</code> is implemented using it.</p>
<p>Suppose we want to make a bunch of trees of different sizes. This would involve mapping our <code>make_tree</code> function over a vector of sizes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sizes &lt;-<span class="st"> </span><span class="dv">3</span>:<span class="dv">8</span>
grp &lt;-<span class="st"> </span>obj$<span class="kw">lapply</span>(sizes, make_tree)</code></pre></div>
<pre><code>## Creating bundle: 'frangible_leafhopper'</code></pre>
<pre><code>## [ bulk      ]  Creating 6 tasks</code></pre>
<pre><code>## submitting 6 tasks</code></pre>
<p>By default, <code>$qlapply</code> returns a “task_bundle” with an automatically generated name. You can customise the name with the <code>name</code> argument.</p>
<p>In contrast to <code>lapply</code> this is not blocking (i.e., submitting tasks and collecting the results is done asynchronously) but if you pass a <code>timeout</code> argument to <code>$lapply</code> then it will poll until the jobs are done, in the same way as <code>wait()</code>, below.</p>
<p>Get the startus of all the jobs</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grp$<span class="kw">status</span>()</code></pre></div>
<pre><code>## 66c9628803e0732a2f77089e7cfe1aac eb3fe74d543a1c536f2f21eb12230c37
##                       &quot;COMPLETE&quot;                       &quot;COMPLETE&quot;
## b31482ebd2ec7bfba39c200aba357278 bd40f274652b284774d31c614496c547
##                       &quot;COMPLETE&quot;                        &quot;PENDING&quot;
## 6c8f9b197a1e74177f6314285f59bbdb 92bc0488694fdfcd361370aeb152b94c
##                        &quot;PENDING&quot;                        &quot;PENDING&quot;</code></pre>
<p>Wait until they are all complete and get the results</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span>grp$<span class="kw">wait</span>(<span class="dv">120</span>)</code></pre></div>
<p>The other bulk interface is where you want to run a function over a combination of parameters. Use <code>queuer::enqueue_bulk</code> here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">a =</span> letters[<span class="dv">1</span>:<span class="dv">3</span>], <span class="dt">b =</span> <span class="kw">runif</span>(<span class="dv">2</span>), <span class="dt">c =</span> pi,
                    <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
pars</code></pre></div>
<pre><code>##   a         b        c
## 1 a 0.9082078 3.141593
## 2 b 0.9082078 3.141593
## 3 c 0.9082078 3.141593
## 4 a 0.2016819 3.141593
## 5 b 0.2016819 3.141593
## 6 c 0.2016819 3.141593</code></pre>
<p>Suppose that we have a function that we want to run over this set of parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">combine</span>(pars$a[[<span class="dv">1</span>]], pars$b[[<span class="dv">1</span>]], pars$c[[<span class="dv">1</span>]])</code></pre></div>
<pre><code>## [1] &quot;a: 4.04980&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grp &lt;-<span class="st"> </span>obj$<span class="kw">enqueue_bulk</span>(pars, combine, <span class="dt">do_call =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Creating bundle: 'auspicial_bunny'</code></pre>
<pre><code>## [ bulk      ]  Creating 6 tasks</code></pre>
<pre><code>## submitting 6 tasks</code></pre>
<p>By default this runs</p>
<ul>
<li><code>combine(a = pars$a[[1]], b = pars$b[[1]], c = pars$c[[1]])</code></li>
<li><code>combine(a = pars$a[[2]], b = pars$b[[2]], c = pars$c[[2]])</code></li>
<li>…</li>
<li><code>combine(a = pars$a[[6]], b = pars$b[[6]], c = pars$c[[6]])</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span>grp$<span class="kw">wait</span>(<span class="dv">120</span>)
res</code></pre></div>
<pre><code>## [[1]]
## [1] &quot;a: 4.04980&quot;
##
## [[2]]
## [1] &quot;b: 4.04980&quot;
##
## [[3]]
## [1] &quot;c: 4.04980&quot;
##
## [[4]]
## [1] &quot;a: 3.34327&quot;
##
## [[5]]
## [1] &quot;b: 3.34327&quot;
##
## [[6]]
## [1] &quot;c: 3.34327&quot;</code></pre>
<p>Running <code>do_call = FALSE</code> would run functions as a row-wise <code>lapply</code>.</p>
</div>
<div id="cancelling-and-stopping-jobs" class="section level2">
<h2>Cancelling and stopping jobs</h2>
<p>Suppose you fire off a bunch of jobs and realise that you have the wrong data or they’re all going to fail - you can stop them fairly easily.</p>
<p>Here’s a job that will run for an hour and return nothing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t &lt;-<span class="st"> </span>obj$<span class="kw">enqueue</span>(<span class="kw">Sys.sleep</span>(<span class="dv">3600</span>))</code></pre></div>
<p>Wait for the job to start up:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">while (t$<span class="kw">status</span>() ==<span class="st"> &quot;PENDING&quot;</span>) {
  <span class="kw">Sys.sleep</span>(.<span class="dv">5</span>)
}</code></pre></div>
<p>Now that it’s started it can be cancelled with the <code>$unsubmit</code> method:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">unsubmit</span>(t$id)</code></pre></div>
<pre><code>## [1] &quot;OK&quot;</code></pre>
<p>unsubmitting multiple times is safe, and will have no effect.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">unsubmit</span>(t$id)</code></pre></div>
<pre><code>## [1] &quot;NOT_RUNNING&quot;</code></pre>
<p>Alternatively you can use <code>obj$task_delete(t$id)</code> which unsubmits the task and then deletes it.</p>
<p>Note that the task is not actually deleted (see below); you can still get at the expression:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">expr</span>()</code></pre></div>
<pre><code>## Sys.sleep(3600)</code></pre>
<p>but you cannot retrieve results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t$<span class="kw">result</span>()</code></pre></div>
<pre><code>## Error: task dbfa16bb6869125e8088907c166bf08f is unfetchable: CANCELLED</code></pre>
<p>The argument to <code>unsubmit</code> can be a vector. For example, to unsubmit a whole task bundle:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grp &lt;-<span class="st"> </span>queuer::<span class="kw">qlapply</span>(<span class="kw">rep</span>(<span class="dv">3600</span>, <span class="dv">4</span>), Sys.sleep, obj)</code></pre></div>
<pre><code>## Creating bundle: 'conservable_okapi'</code></pre>
<pre><code>## [ bulk      ]  Creating 4 tasks</code></pre>
<pre><code>## submitting 4 tasks</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">unsubmit</span>(grp$ids)</code></pre></div>
<pre><code>## [1] &quot;OK&quot; &quot;OK&quot; &quot;OK&quot; &quot;OK&quot;</code></pre>
<div id="deleting-jobs" class="section level3">
<h3>Deleting jobs</h3>
<p>Deleting tasks is supported but it isn’t entirely encouraged. Not all of the functions behave well with missing tasks, so if you delete things and still have old task handles floating around you might get confusing results.</p>
<p>There is a delete method (<code>obj$delete</code>) that will delete jobs, first unsubmitting it if it has been submitted. It takes a vector of task ids as an argument.</p>
</div>
</div>
</div>
<div id="misc" class="section level1">
<h1>Misc</h1>
<div id="jobs-that-require-compiled-code" class="section level2">
<h2>Jobs that require compiled code</h2>
<p>If you are running stan, or Rcpp with <code>sourceCpp</code> (in the latter case you <em>should</em> be using a package) you’ll need a working compiler. For rstan this is detected automatically. But in general, pass <code>rtools = TRUE</code> to <code>queue_didehpc()</code>.</p>
</div>
<div id="parallel-computation-on-the-cluster" class="section level2">
<h2>Parallel computation on the cluster</h2>
<p>If you are running tasks that can use more than one core, you can request more resources for your task and use process level parallism with the <code>parallel</code> package. To request 8 cores, you could run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">didehpc::<span class="kw">didehpc_config</span>(<span class="dt">cores =</span> <span class="dv">8</span>)</code></pre></div>
<p>When your task starts, 8 cores will be allocated to it and a <code>parallel</code> cluster will be created. You can use it with things like <code>parallel::parLapply</code>, specifying <code>cl</code> as <code>NULL</code>. So if within your cluster job you needed to apply function <code>f</code> to a each element of a list <code>x</code>, you could write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">run_f &lt;-<span class="st"> </span>function(x) {
  parallel::<span class="kw">parLapply</span>(<span class="ot">NULL</span>, x, f)
}
obj$<span class="kw">enqueue</span>(<span class="kw">run_f</span>(x))</code></pre></div>
<p>The parallel bits can be embedded within larger blocks of code. All functions in <code>parallel</code> that take <code>cl</code> as a first argument can be used. You do not need to (and should not) set up the cluster as this will happen automatically as the job starts.</p>
<p>Alternatively, if you want to control cluster creation (e.g., you are using software that does this for you) then, pass <code>parallel = FALSE</code> to the config call:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">didehpc::<span class="kw">didehpc_config</span>(<span class="dt">cores =</span> <span class="dv">8</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>In this case you are responsible for setting up the cluster.</p>
<p>As an alternative to requesting cores, you can use a different job template:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">didehpc::<span class="kw">didehpc_config</span>(<span class="dt">template =</span> <span class="st">&quot;16Core&quot;</span>)</code></pre></div>
<p>which will reserve you the entire node. Again, a cluster will be started with all availabe cores unless you also specify <code>parallel = FALSE</code>.</p>
</div>
<div id="running-heaps-of-jobs-without-annoying-your-colleagues" class="section level2">
<h2>Running heaps of jobs without annoying your colleagues</h2>
<p>If you have thousands and thousands of jobs to submit at once you may not want to flood the cluster with them all at once. Each job submission is relatively slow (the HPC tools that the web interface has to use are relatively slow). The actual queue that the cluster uses doesn’t seem to like processing tens of thousands of job, and can slow down. And if you take up the whole cluster someone may come and knock on your office and complain at you. At the same time, batching your jobs up into little bits and manually sending them off is a pain and work better done by a computer.</p>
<p>An alternative is to submit a set of “workers” to the cluster, and then submit jobs to them. This is done with the <a href="https://github.com/richfitz/rrq"><code>rrq</code></a> package, along with a <a href="http://redis.io"><code>redis</code></a> server running on the cluster.</p>
<p>See the “workers” vignette for details.</p>
</div>
<div id="rstan" class="section level2">
<h2><code>rstan</code></h2>
<p>To use parallel chains, do something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">config &lt;-<span class="st"> </span>didehpc::<span class="kw">didehpc_config</span>(<span class="dt">cores =</span> <span class="dv">4</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
obj &lt;-<span class="st"> </span>didehpc::<span class="kw">queue_didehpc</span>(ctx, config)</code></pre></div>
<p>to request four cores or</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">config &lt;-<span class="st"> </span>didehpc::<span class="kw">didehpc_config</span>(<span class="dt">wholenode =</span> <span class="ot">TRUE</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
obj &lt;-<span class="st"> </span>didehpc::<span class="kw">queue_didehpc</span>(ctx, config)</code></pre></div>
<p>to request a whole node. The <code>parallel = FALSE</code> tells the system not to set up a cluster for use with the <code>parallel</code> pacakge. However, you’ll still need to specify options(mc.cores) appropriately and I don’t expose that yet…</p>
</div>
<div id="using-microsoft-hpc-tools" class="section level2">
<h2>Using Microsoft HPC tools</h2>
<p>This section is only relevant for Windows users who are used to using the Windows Job Manager software in Microsoft HPC Pack.</p>
<p>If you have used the cluster tools from windows before, then you may be used to seeing your name show up in the HPC job manager. By default if you submit jobs with this tool, you will not see that as they’re actually submitted by a process on the cluster but run <em>as</em> you. See the <a href="https://mrcdata.dide.ic.ac.uk/wiki/index.php/HPC_Web_Portal#Notes_for_Windows_Job_Manager_Users">cluster wiki</a> for more information.</p>
<p>If you want this behaviour back, <code>didehpc</code> can be configured to use the HPC tools on your computer. Just run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">didehpc::<span class="kw">didehpc_config_global</span>(<span class="dt">hpctools =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>or</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">didehpc.hpctools =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>before creating the queue, or run</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj &lt;-<span class="st"> </span>didehpc::<span class="kw">queue</span>(ctx, <span class="dt">config =</span> didehpc::<span class="kw">didehpc_config</span>(<span class="dt">hpctools =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p>This is experimental but I welcome feedback.</p>
</div>
</div>
<div id="mapping-network-drives" class="section level1">
<h1>Mapping network drives</h1>
<p>For all operating systems, if you are on the wireless network you will need to connect to the VPN. If you can get on a wired network you’ll likely have a better time because the VPN and wireless network seems less stable in general. Instructions for setting up a VPN are <a href="https://www1.imperial.ac.uk/publichealth/departments/ide/it/remote">here</a></p>
<div id="windows" class="section level2">
<h2>Windows</h2>
<p>Your network drives are likely already mapped for you. In fact you should not even need to map drives as fully qualified network names (e.g. <code>//fi--didef2/tmp</code>) should work for you.</p>
</div>
<div id="mac-osx" class="section level2">
<h2>Mac OS/X</h2>
<p>In Finder, go to <code>Go -&gt; Connect to Server...</code> or press <code>Command-K</code>. In the address field write the name of the share you want to connect to. Useful ones are</p>
<ul>
<li><code>smb://fi--san03.dide.ic.ac.uk/homes/&lt;username&gt;</code> – your home share</li>
<li><code>smb://fi--didef2.dide.ic.ac.uk/tmp</code> – the temporary share</li>
</ul>
<p>At some point in the process you should get prompted for your username and password, but I can’t remember what that looks like.</p>
<p>These directories will be mounted at <code>/Volumes/&lt;username&gt;</code> and <code>/Volumes/tmp</code> (so the last bit of the filename will be used as the mountpoint within <code>Volumes</code>). There may be a better way of doing this, and the connection will not be restablished automatically so if anyone has a better way let me know.</p>
</div>
<div id="linux" class="section level2">
<h2>Linux</h2>
<p>This is what I have done for my computer and it seems to work, though it’s not incredibly fast. Full instructions are <a href="https://help.ubuntu.com/community/MountWindowsSharesPermanently">on the Ubuntu community wiki</a>.</p>
<p>First, install cifs-utils</p>
<pre><code>sudo apt-get install cifs-utils</code></pre>
<p>In your <code>/etc/fstab</code> file, add</p>
<pre><code>//fi--san03/homes/&lt;dide-username&gt; &lt;home-mount-point&gt; cifs uid=&lt;local-userid&gt;,gid=&lt;local-groupid&gt;,credentials=/home/&lt;local-username&gt;/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0
//fi--didef2/tmp &lt;tmp-mount-point&gt; cifs uid=&lt;local-userid&gt;,gid=&lt;local-groupid&gt;,credentials=/home/&lt;local-username&gt;/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0</code></pre>
<p>where:</p>
<ul>
<li><code>&lt;dide-username&gt;</code> is your dide username without the <code>DIDE\</code> bit.</li>
<li><code>&lt;local-username&gt;</code> is your local username (i.e., <code>echo $USER</code>).</li>
<li><code>&lt;local-userid&gt;</code> is your local numeric user id (i.e. <code>id -u $USER</code>)</li>
<li><code>&lt;local-groupid&gt;</code> is your local numeric group id (i.e. <code>id -g $USER</code>)</li>
<li><code>&lt;home-mount-point&gt;</code> is where you want your DIDE home directory mounted</li>
<li><code>&lt;tmp-mount-point&gt;</code> is where you want the DIDE temporary directory mounted</li>
</ul>
<p><strong>please back this file up before editing</strong>.</p>
<p>So for example, I have:</p>
<pre><code>//fi--san03/homes/rfitzjoh /home/rich/net/home cifs uid=1000,gid=1000,credentials=/home/rich/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0
//fi--didef2/tmp /home/rich/net/temp cifs uid=1000,gid=1000,credentials=/home/rich/.smbcredentials,domain=DIDE,sec=ntlmssp,iocharset=utf8 0  0</code></pre>
<p>The file <code>.smbcredentials</code> contains</p>
<pre><code>username=&lt;dide-username&gt;
password=&lt;dide-password&gt;</code></pre>
<p>and set this to be chmod 600 for a modicum of security, but be aware your password is stored in plaintext.</p>
<p>This set up is clearly insecure. I believe if you omit the credentials line you can have the system prompt you for a password interactively, but I’m not sure how that works with automatic mounting.</p>
<p>Finally, run</p>
<pre><code>mount -a</code></pre>
<p>to mount all drives and with any luck it will all work and you don’t have to do this until you get a new computer.</p>
</div>
</div>
<div id="running-out-of-place" class="section level1">
<h1>Running out of place</h1>
<p>The instructions above require that you are running on a network drive. This might be inconvenient for people who run off the private network (e.g., mac users) or where you want to run things on the cluster part way through a project and don’t want to copy everything over to a network drive.</p>
<p>In this case there is (experimental) support for running “out of place” where the interaction with the cluster happens in a different directory to where your R session is running and where your files reside. The wrinkle is getting the files you need synchronised.</p>
<p>To do the syncronisation we use <code>rsync</code> via the <a href="https://github.com/richfitz/syncr"><code>syncr</code></a> package Install it with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">drat:::<span class="kw">add</span>(<span class="st">&quot;mrc-ide&quot;</span>)
<span class="kw">install.packages</span>(<span class="st">&quot;syncr&quot;</span>)</code></pre></div>
<p>Then, when constructing the queue, you need to specify a working directory for the cluster that is on the shared drive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">workdir &lt;-<span class="st"> &quot;Q:/cluster/context&quot;</span>
didehpc::<span class="kw">didehpc_config_global</span>(<span class="dt">workdir =</span> workdir)</code></pre></div>
<p>When you construct the context, that needs to be on a network share, so you might write:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">root &lt;-<span class="st"> </span><span class="kw">file.path</span>(workdir, <span class="st">&quot;contexts&quot;</span>)
ctx &lt;-<span class="st"> </span>context::<span class="kw">context_save</span>(root, <span class="dt">packages =</span> <span class="st">&quot;ape&quot;</span>, <span class="dt">sources =</span> <span class="st">&quot;mysources.R&quot;</span>)</code></pre></div>
<p>Then construct the queue as normal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj &lt;-<span class="st"> </span>didehpc::<span class="kw">queue_didehpc</span>(ctx)</code></pre></div>
<p>This will automatically syncronise the sources, copying them if they need updating.</p>
<p>You can also specify additional files to synchronise with the <code>sync</code> argument to <code>queue_didehpc</code>.</p>
<p>If you had other files to synchronise they would be listed with the argument <code>sync</code> to <code>queue_didehpc</code>. You can update the remote files by running</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obj$<span class="kw">sync_files</span>()</code></pre></div>
<p>at any time.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
